{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification based on  magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File data/train.csv does not exist: 'data/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d56de844c733>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Read the file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/train.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Evaluate extinction corrected magnitude\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\condaa\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\condaa\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\condaa\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\condaa\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\condaa\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File data/train.csv does not exist: 'data/train.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "c =[]\n",
    "# Read the file\n",
    "data = pd.read_csv(\"data/train.csv\")\n",
    "\n",
    "# Evaluate extinction corrected magnitude\n",
    "u = data['petroMag_u']-data['extinction_u']\n",
    "r = data['petroMag_r']-data['extinction_r']\n",
    "\n",
    "# Combine the columns generated with the original data frame\n",
    "data['u'] = u.values\n",
    "data['r'] = r.values\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    if (row['u'] - row['r'] > 2.2):\n",
    "        c.append(0)\n",
    "    else:\n",
    "        c.append(1)\n",
    "\n",
    "# Print the accuracy score\n",
    "prediction = np.array(c)\n",
    "correct = np.array(data['moving'])\n",
    "accuracy_score(correct, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "%matplotlib inline\n",
    "font = {'family' : 'serif',\n",
    "        'size'   : 14}\n",
    "\n",
    "mpl.rc('font', **font)\n",
    "\n",
    "# Identify the correct Spirals\n",
    "xx = data['u'].mask(correct.astype('bool'))\n",
    "yy = data['r'].mask(correct.astype('bool'))\n",
    "\n",
    "# Identify the predicted spirals\n",
    "x = data['u'].mask(prediction.astype('bool'))\n",
    "y = data['r'].mask(prediction.astype('bool'))\n",
    "#data.plot.scatter('u','r')\n",
    "#plt.plot(u, r, 'k.')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "ax.get_xaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())\n",
    "ax.get_yaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())\n",
    "\n",
    "plt.plot(xx,yy, 'bo', label=\"Actual\")\n",
    "plt.plot(x, y, 'r+', label=\"Predicted\")\n",
    "plt.xlabel('u')\n",
    "plt.ylabel('r')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Support Vector Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import matplotlib\n",
    "\n",
    "# Define the classifier, where kernel must be one of ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’ or ‘precomputed’.\n",
    "clf = svm.SVC(kernel='linear')\n",
    "\n",
    "# Train the classifier on the training set: size of [1000,2]\n",
    "train_in = np.column_stack((u.values, r.values))\n",
    "train_out = correct\n",
    "\n",
    "clf.fit(train_in, train_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the accuracy of the SVM classifier by plotting the regression line to see if it really\n",
    "# separates the two types of galaxies on u-r plane.\n",
    "\n",
    "# Weights assigned to the features (features are 'spiral' and 'elliptical' in our case)\n",
    "w = clf.coef_[0] \n",
    "slope = - w[0] / w[1]\n",
    "\n",
    "line_x = np.linspace(np.amin(u.values), np.amax(u.values))\n",
    "line_y = slope * line_x - clf.intercept_[0] / w[1]\n",
    "\n",
    "svm_regression = 'r = ' + str(round(slope,2)) + r'$\\times$u + ' + str(round(-1.0*clf.intercept_[0] / w[1],2))\n",
    "\n",
    "# Plot the regression lines\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "ax.get_xaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())\n",
    "ax.get_yaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())\n",
    "\n",
    "plt.scatter((train_in[:, 0])[train_out == 0], (train_in[:, 1])[train_out == 0], label='Spirals', alpha=0.3, s = 70)\n",
    "plt.scatter((train_in[:, 0])[train_out == 1], (train_in[:, 1])[train_out == 1], label='Ellipticals', alpha=0.3, s = 70)\n",
    "\n",
    "plt.plot(line_x, line_y, 'k-', label=\"Linear Regression from SVM: \" + svm_regression)\n",
    "plt.plot(line_x, line_x - 2.2, 'm-', label=\"Linear Regression expected:  r = u - 2.2\")\n",
    "\n",
    "plt.ylim([12,19])\n",
    "plt.xlabel('u')\n",
    "plt.ylabel('r')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on training set itself\n",
    "train_pred = clf.predict(train_in)\n",
    "\n",
    "# Accuracy score\n",
    "accuracy_score(train_out, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on testing set of 250 objects\n",
    "test_data = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "# Evaluate extinction corrected magnitude\n",
    "test_u = test_data['petroMag_u'] - test_data['extinction_u']\n",
    "test_r = test_data['petroMag_r'] - test_data['extinction_r']\n",
    "\n",
    "# Combine the columns generated with the original data frame\n",
    "test_data['u'] = test_u.values\n",
    "test_data['r'] = test_r.values\n",
    "\n",
    "# Testing data\n",
    "test_in = np.column_stack((test_u.values, test_r.values))\n",
    "test_pred = clf.predict(test_in)\n",
    "test_correct = np.array(test_data['moving'])\n",
    "\n",
    "# Accuracy score\n",
    "accuracy_score(test_correct, test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: Using Neural network for more rigorous training\n",
    "\n",
    "Train the neural network on different colors for classifying to check if other colors can help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the files and prepare training and test matrices\n",
    "color_data = pd.read_csv(\"data/train_colors.csv\")\n",
    "\n",
    "# Calculate dereddended colors\n",
    "u_g = color_data['dered_u'] - color_data['dered_g']\n",
    "g_r = color_data['dered_g'] - color_data['dered_r']\n",
    "r_i = color_data['dered_r'] - color_data['dered_i']\n",
    "i_z = color_data['dered_i'] - color_data['dered_z']\n",
    "\n",
    "# Combine the columns generated with the original data frame\n",
    "color_data['u_g'] = u_g.values\n",
    "color_data['g_r'] = g_r.values\n",
    "color_data['r_i'] = r_i.values\n",
    "color_data['i_z'] = i_z.values\n",
    "\n",
    "train_in_colors = np.column_stack((u_g.values, g_r.values, r_i.values, i_z.values))\n",
    "train_out_colors = np.array(color_data['spiral'])\n",
    "\n",
    "# Testing data\n",
    "color_test_data = pd.read_csv(\"data/test_colors.csv\")\n",
    "\n",
    "# Calculate dereddended colors\n",
    "tu_g = color_test_data['dered_u'] - color_test_data['dered_g']\n",
    "tg_r = color_test_data['dered_g'] - color_test_data['dered_r']\n",
    "tr_i = color_test_data['dered_r'] - color_test_data['dered_i']\n",
    "ti_z = color_test_data['dered_i'] - color_test_data['dered_z']\n",
    "\n",
    "# Prepare test matrix and expected output\n",
    "test_in_colors = np.column_stack((tu_g.values, tg_r.values, tr_i.values, ti_z.values))\n",
    "test_out_colors = np.array(color_test_data['spiral'])\n",
    "\n",
    "print(\"Size of the training matrix: \", np.shape(train_in_colors), np.shape(train_out_colors))\n",
    "print(\"Size of the test matrix:     \", np.shape(test_in_colors), np.shape(test_out_colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.utils import plot_model\n",
    "import pydot\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Design a neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=4, activation='relu'))\n",
    "model.add(Dense(3, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "plot_model(model, to_file='data/model.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "# Fit the model\n",
    "model_info = model.fit(train_in_colors, train_out_colors, epochs=150, batch_size=10, validation_split=0.3, \n",
    "                       shuffle=True, verbose=2)\n",
    "# evaluate the model\n",
    "scores = model.evaluate(train_in_colors, train_out_colors)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the trained model\n",
    "test_pred_colors = model.predict(test_in_colors)\n",
    "\n",
    "# Prediction are in probabilities. Round them to convert into binary sequence\n",
    "test_pred_colors = np.around(test_pred_colors)\n",
    "\n",
    "# Print accuracy score\n",
    "accuracy_score(test_out_colors, test_pred_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Accuracy and/or Loss as a Function of Number of Epoch\n",
    "\n",
    "def plot_model_history(model_history):\n",
    "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
    "    # summarize history for accuracy\n",
    "    axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n",
    "    axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n",
    "    axs[0].set_title('Model Accuracy')\n",
    "    axs[0].set_ylabel('Accuracy')\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].get_xaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())\n",
    "    axs[0].get_yaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())\n",
    "    axs[0].legend(['train', 'val'], loc='best')\n",
    "    # axs[0].tick_params(top=True, right=True, labeltop=True, labelright=True, which='both')\n",
    "    \n",
    "    # summarize history for loss\n",
    "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
    "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
    "    axs[1].set_title('Model Loss')\n",
    "    axs[1].set_ylabel('Loss')\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].get_xaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())\n",
    "    axs[1].get_yaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())\n",
    "    axs[1].legend(['train', 'val'], loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "plot_model_history(model_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 10-fold cross validation for shuffling the validation sample\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "cvscores = []\n",
    "for train, test in kfold.split(train_in_colors, train_out_colors):\n",
    "  # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=4, activation='relu'))\n",
    "    model.add(Dense(3, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # Fit the model\n",
    "    model.fit(train_in_colors[train], train_out_colors[train], epochs=150, batch_size=10, verbose=0)\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(train_in_colors[test], train_out_colors[test], verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the trained model\n",
    "test_pred_colors = model.predict(test_in_colors)\n",
    "\n",
    "# Prediction are in probabilities. Round them to convert into binary sequence\n",
    "test_pred_colors = np.around(test_pred_colors)\n",
    "\n",
    "# Print accuracy score\n",
    "accuracy_score(test_out_colors, test_pred_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: Using Convolutional based classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are using keras framework with tensorflow as the backend\n",
    "# Convolutional Neural Networks are multi-layer neural networks that assume the input data to be images.\n",
    "\n",
    "# Sequential is simply a linear stack of neural network layers, and it's perfect for the type of \n",
    "# feed-forward CNN\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Import the core layers from Keras which are used in almost any neural network\n",
    "from keras.layers import Dense, Flatten\n",
    "\n",
    "# Import CNN layers from Keras that will help us efficiently train on image data\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "# Helps to preprocess the images\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your model\n",
    "model = Sequential()\n",
    "\n",
    "# Add first convolutional layer. A full-color image with all 3 RGB channels will have a depth of 3.\n",
    "model.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "\n",
    "# Define the maxpooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "\n",
    "# Layer which Flatten the data\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add more layers to the network\n",
    "model.add(Dense(units = 128, activation = 'relu'))\n",
    "model.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "# We need to compile the model. Declare the loss function and the optimizer (SGD, Adam, etc.).\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the images\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "# Define the training and test set\n",
    "training_set = train_datagen.flow_from_directory('data/Training', target_size = (64, 64), batch_size = 32, class_mode = 'binary')\n",
    "test_set = test_datagen.flow_from_directory('data/Testing',target_size = (64, 64), batch_size = 32, class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train your model\n",
    "model.fit_generator(training_set, steps_per_epoch = 8000, epochs = 2, validation_data = test_set, validation_steps = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
